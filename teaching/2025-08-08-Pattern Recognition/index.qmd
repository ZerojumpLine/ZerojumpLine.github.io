---
title: "Pattern Recognition 2025"
author: Zeju Li
date: 2025-09-01
slug: PR-2025
image: featured.jpg
categories:
  - Ph.D.
  - BME
subtitle: "An advanced, discussion-based course for Ph.D. students."
description: ''
format: 
  html: 
    page-layout: full
links:
  - icon: journal-text
    name: EST60033.02
    url: https://elearning.fudan.edu.cn/courses/100620
---
I teach a pattern recognition course for BME Ph.D. students. In this course, I will cover some advanced concepts of AI.

## Description
This course aims to equip Ph.D. students with a deep understanding of modern pattern recognition theory and cutting-edge innovation capabilities. The curriculum covers five key areas: fundamental theories, discriminative models, reinforcement learning, generative models, and emerging topics such as robustness and fairness.

The course emphasizes the integration of theory and practice, requiring students to master end-to-end research methodologies‚Äîfrom mathematical derivation to engineering implementation‚Äîwhile fostering cross-domain innovation. Upon completion, Ph.D. students will possess the academic competence to publish in top-tier conferences.

This course takes place in JA302 every Thursday afternoon (14:25-17:05) during the first semester of the 2025-2026 academic year.

## Expectations

### Prerequisites

- **Ph.D. student** in a relevant field
- **Python proficiency** is required
- **Strong foundation** in mathematics and AI fundamentals

### Course Requirements

- **Paper presentation** (in pairs of 2)
- **Final deliverable**: research draft paper or scientific blog post

## Welcome & What's Ahead 

Here is some examples of what will be covered in this course.

### Representation Learning

Instead of a human engineer manually designing features (like edges, shapes, or specific keywords), the machine learns to identify the most useful ways to represent the data for the problem at hand.

Here is an example of the two-moon representation: [This figure is interactive and was created using Plotly. It's great, isn't it?]{.aside}

```{python}
#| echo: false
#| output: true
import plotly.graph_objects as go
import numpy as np
from sklearn.datasets import make_moons
from sklearn.model_selection import train_test_split
from sklearn.neighbors import KNeighborsClassifier

# Parameters for visualization
mesh_size = .02
margin = 0.25

# Load and split data
X, y = make_moons(noise=0.3, random_state=0)
X_train, X_test, y_train, y_test = train_test_split(
    X, y.astype(str), test_size=0.25, random_state=0)

# Create a mesh grid for decision boundary
x_min, x_max = X[:, 0].min() - margin, X[:, 0].max() + margin
y_min, y_max = X[:, 1].min() - margin, X[:, 1].max() + margin
xrange = np.arange(x_min, x_max, mesh_size)
yrange = np.arange(y_min, y_max, mesh_size)
xx, yy = np.meshgrid(xrange, yrange)

# Train K-Nearest Neighbors classifier
clf = KNeighborsClassifier(15, weights='uniform')
clf.fit(X, y)
Z = clf.predict_proba(np.c_[xx.ravel(), yy.ravel()])[:, 1]
Z = Z.reshape(xx.shape)

# Define trace specifications for different data splits
trace_specs = [
    [X_train, y_train, '0', 'Train', 'square'],
    [X_train, y_train, '1', 'Train', 'circle'],
    [X_test, y_test, '0', 'Test', 'square-dot'],
    [X_test, y_test, '1', 'Test', 'circle-dot']
]

# Create the main figure
fig = go.Figure(data=[
    go.Scatter(
        x=X[y==label, 0], y=X[y==label, 1],
        name=f'{split} Split, Label {label}',
        mode='markers', marker_symbol=marker
    )
    for X, y, label, split, marker in trace_specs
])

# Style the markers
fig.update_traces(
    marker_size=12, marker_line_width=1.5,
    marker_color="lightyellow"
)

# Add decision boundary contour
fig.add_trace(
    go.Contour(
        x=xrange,
        y=yrange,
        z=Z,
        showscale=False,
        colorscale='RdBu',
        opacity=0.4,
        name='Decision Boundary',
        hoverinfo='skip'
    )
)

# Apply beautiful styling
fig.update_layout(
    title=dict(
        text="Machine Learning: Decision Boundary Visualization",
        font=dict(size=18, color="#2c3e50"),
        x=0.5
    ),
    xaxis_title="Feature 1",
    yaxis_title="Feature 2",
    width=700,
    height=500,
    plot_bgcolor='white',
    font=dict(family="Arial, sans-serif", size=12, color="#2c3e50"),
    showlegend=True,
    legend=dict(
        yanchor="top", y=0.99, xanchor="left", x=0.01,
        bgcolor="rgba(255,255,255,0.9)", bordercolor="#bdc3c7", borderwidth=1
    )
)

fig.show()
```

### Discriminative Models

It directly learns to map input features ($X$) to output labels or classes ($Y$) by modeling the conditional probability $P(Y|X)$.

Here's an example using Support Vector Regression on the famous Iris dataset: [Try to rotate this figure and observe how the surface is fitted to the dots.]{.aside}

```{python}
#| echo: false
#| output: true
import numpy as np
import pandas as pd
import plotly.express as px
import plotly.graph_objects as go
from sklearn.svm import SVR

# Parameters for visualization
mesh_size = .02
margin = 0

# Load the famous Iris dataset
df = px.data.iris()

# Prepare features and target
X = df[['sepal_width', 'sepal_length']]
y = df['petal_width']

# Train Support Vector Regression model
model = SVR(C=1.)
model.fit(X, y)

# Create a mesh grid for surface prediction
x_min, x_max = X.sepal_width.min() - margin, X.sepal_width.max() + margin
y_min, y_max = X.sepal_length.min() - margin, X.sepal_length.max() + margin
xrange = np.arange(x_min, x_max, mesh_size)
yrange = np.arange(y_min, y_max, mesh_size)
xx, yy = np.meshgrid(xrange, yrange)

# Generate predictions on the mesh grid
# Convert mesh grid to DataFrame to avoid feature name warning
mesh_df = pd.DataFrame(np.c_[xx.ravel(), yy.ravel()], columns=['sepal_width', 'sepal_length'])
pred = model.predict(mesh_df)
pred = pred.reshape(xx.shape)

# Create the 3D scatter plot
fig = px.scatter_3d(df, x='sepal_width', y='sepal_length', z='petal_width',
                    title="3D Regression: Petal Width Prediction",
                    labels={'sepal_width': 'Sepal Width', 'sepal_length': 'Sepal Length', 'petal_width': 'Petal Width'})

# Style the scatter points
fig.update_traces(marker=dict(size=5, opacity=0.8))

# Add the regression surface
fig.add_traces(go.Surface(
    x=xrange, 
    y=yrange, 
    z=pred, 
    name='Regression Surface',
    opacity=0.6,
    colorscale='Viridis'
))

# Apply beautiful 3D styling
fig.update_layout(
    scene=dict(
        bgcolor='white',
        xaxis=dict(showgrid=True, gridcolor='#ecf0f1'),
        yaxis=dict(showgrid=True, gridcolor='#ecf0f1'),
        zaxis=dict(showgrid=True, gridcolor='#ecf0f1'),
        camera=dict(eye=dict(x=1.5, y=1.5, z=1.5))
    ),
    font=dict(family="Arial, sans-serif", size=12, color="#2c3e50"),
    title=dict(
        text="3D Regression: Petal Width Prediction",
        font=dict(size=18, color="#2c3e50"),
        x=0.5
    ),
    width=700,
    height=500
)

fig.show()
```
### Generative Models

It is a statistical model that learns the underlying probability distribution of the data with the goal of understanding how the data is "generated."

Here's an interactive example based on flow matching showing the transformation from a Gaussian distribution to a more complex multimodal distribution: [I like the idea of flow matching as it is particularly useful in generative modeling, where we want to learn to transform noise into realistic data samples while maintaining the ability to compute exact likelihoods and perform efficient sampling.]{.aside}

```{python}
#| echo: false
#| output: true
import plotly.graph_objects as go
import plotly.express as px
from plotly.subplots import make_subplots
import numpy as np
from scipy.stats import multivariate_normal
import pandas as pd

# Set random seed for reproducibility
np.random.seed(42)

# Define the source and target distributions
def source_density(x, y):
    """Source: 2D Gaussian distribution"""
    mean = [0, 0]
    cov = [[1, 0.3], [0.3, 1]]
    return multivariate_normal.pdf(np.column_stack([x.ravel(), y.ravel()]), mean, cov).reshape(x.shape)

def target_density(x, y):
    """Target: Mixture of two Gaussians"""
    mean1, cov1 = [2, 2], [[0.5, 0.1], [0.1, 0.5]]
    mean2, cov2 = [-2, -2], [[0.8, -0.2], [-0.2, 0.8]]
    
    pdf1 = multivariate_normal.pdf(np.column_stack([x.ravel(), y.ravel()]), mean1, cov1).reshape(x.shape)
    pdf2 = multivariate_normal.pdf(np.column_stack([x.ravel(), y.ravel()]), mean2, cov2).reshape(x.shape)
    return 0.6 * pdf1 + 0.4 * pdf2

# Create grid for density visualization
x = np.linspace(-4, 4, 50)
y = np.linspace(-4, 4, 50)
X, Y = np.meshgrid(x, y)

# Generate flow matching trajectory
def flow_matching_trajectory(t):
    """Simple linear interpolation between source and target"""
    return (1 - t) * source_density(X, Y) + t * target_density(X, Y)

# Create animation frames
n_frames = 30
frames = []
for i in range(n_frames):
    t = i / (n_frames - 1)
    density = flow_matching_trajectory(t)
    
    # Create contour plot for each frame
    frame = go.Frame(
        data=[
            go.Contour(
                x=x, y=y, z=density,
                colorscale='Plasma',
                showscale=False,
                opacity=0.9,
                line=dict(width=0.5, color='rgba(255,255,255,0.3)'),
                contours=dict(
                    showlines=True,
                    start=0,
                    end=np.max(density),
                    size=np.max(density)/12,
                    coloring='heatmap'
                )
            )
        ],
        name=f"frame_{i}"
    )
    frames.append(frame)

# Create initial figure
fig = go.Figure(
    data=[
        go.Contour(
            x=x, y=y, z=source_density(X, Y),
            colorscale='Plasma',
            showscale=False,
            opacity=0.9,
            line=dict(width=0.5, color='rgba(255,255,255,0.3)'),
            contours=dict(
                showlines=True,
                start=0,
                end=np.max(source_density(X, Y)),
                size=np.max(source_density(X, Y))/12,
                coloring='heatmap'
            )
        )
    ],
    frames=frames
)

# Add animation controls
fig.update_layout(
    title=dict(
        text="Flow Matching: Gaussian ‚Üí Multimodal Distribution",
        font=dict(size=20, color="#1a1a1a", family="Inter, -apple-system, BlinkMacSystemFont, sans-serif"),
        x=0.5
    ),
    xaxis_title="X",
    yaxis_title="Y",
    width=700,
    height=650,
    plot_bgcolor='#fafafa',
    paper_bgcolor='#ffffff',
    font=dict(family="Inter, -apple-system, BlinkMacSystemFont, sans-serif", size=13, color="#1a1a1a"),
    xaxis=dict(
        gridcolor='rgba(0,0,0,0.1)',
        linecolor='rgba(0,0,0,0.2)',
        tickcolor='rgba(0,0,0,0.2)',
        title_font=dict(size=14, color="#1a1a1a")
    ),
    yaxis=dict(
        gridcolor='rgba(0,0,0,0.1)',
        linecolor='rgba(0,0,0,0.2)',
        tickcolor='rgba(0,0,0,0.2)',
        title_font=dict(size=14, color="#1a1a1a")
    ),
    updatemenus=[
        dict(
            type="buttons",
            direction="left",
            buttons=list([
                dict(
                    args=[None, {"frame": {"duration": 100, "redraw": True},
                                "fromcurrent": True, "transition": {"duration": 50}}],
                    label="‚ñ∂Ô∏è Play",
                    method="animate"
                ),
                dict(
                    args=[[None], {"frame": {"duration": 0, "redraw": True},
                                   "mode": "immediate", "transition": {"duration": 0}}],
                    label="‚è∏Ô∏è Pause",
                    method="animate"
                )
            ]),
            pad={"r": 15, "t": 100},
            showactive=False,
            x=0.2,
            xanchor="right",
            y=0.10,
            yanchor="top",
            bgcolor='rgba(255,255,255,0.9)',
            bordercolor='rgba(0,0,0,0.1)',
            borderwidth=1
        )
    ],
    sliders=[
        dict(
            active=0,
            yanchor="top",
            xanchor="left",
            currentvalue={"font": {"size": 16, "color": "#1a1a1a", "family": "Inter, sans-serif"}, "prefix": "Time: ", "visible": True, "xanchor": "right"},
            transition={"duration": 300, "easing": "cubic-in-out"},
            pad={"b": 20, "t": 60},
            len=0.9,
            x=0.05,
            y=0,
            bgcolor='rgba(255,255,255,0.9)',
            bordercolor='rgba(0,0,0,0.1)',
            borderwidth=1,
            tickcolor='#6366f1',
            ticklen=8,
            tickwidth=2,
            steps=[
                dict(
                    args=[[f"frame_{i}"], {"frame": {"duration": 100, "redraw": True},
                                           "mode": "immediate", "transition": {"duration": 50}}],
                    label=f"{i/(n_frames-1):.2f}",
                    method="animate"
                )
                for i in range(n_frames)
            ]
        )
    ]
)

# Add annotations for source and target
fig.add_annotation(
    x=0, y=0, xref="x", yref="y",
    text="Source<br>(Gaussian)",
    showarrow=True,
    arrowhead=2,
    arrowsize=1.2,
    arrowwidth=2.5,
    arrowcolor="#6366f1",
    ax=25, ay=-35,
    font=dict(size=13, color="#1a1a1a", family="Inter, sans-serif"),
    bgcolor='rgba(255,255,255,0.9)',
    bordercolor='rgba(99,102,241,0.3)',
    borderwidth=1
)

fig.add_annotation(
    x=2, y=2, xref="x", yref="y",
    text="Target<br>(Multimodal)",
    showarrow=True,
    arrowhead=2,
    arrowsize=1.2,
    arrowwidth=2.5,
    arrowcolor="#ef4444",
    ax=25, ay=-35,
    font=dict(size=13, color="#1a1a1a", family="Inter, sans-serif"),
    bgcolor='rgba(255,255,255,0.9)',
    bordercolor='rgba(239,68,68,0.3)',
    borderwidth=1
)

fig.show()
```

## Schedule

### Module 1: Basic Theory

| Week | Date | Lesson 1 | Lesson 2 | Lesson 3 | Materials |
|:----:|:----:|:--------:|:--------:|:--------:|:---------:|
| **1** | 09/11/2025 | *Lecture* | *Lecture* | *Lecture* | [Slides](lecture_1.pdf) |
| **2** | 09/18/2025 | *Lecture* | üßëüèº‚Äçüè´üë©üèº‚Äçüè´<span style="color: darkred !important;">*Presentation I*</span> | *Coding I* | [Slides](lecture_2.pdf)<br> [PCA](code_1_pca.ipynb), [Linear Regression](code_1_linear_regression.ipynb), [GMM](code_1_gmm.ipynb) |
| **3** | 09/25/2025 | *Reading*^1^ | *Reading*^2^ | *Reading*^3^ | |
| **4** | 10/02/2025 | *Reading*^4^ | *Reading*^5^ | *Reading*^6^ | |


^1^ Understanding black-box predictions via influence functions, 2017 [Read paper](https://proceedings.mlr.press/v70/koh17a?ref=https://githubhelp.com)<br>[Those classic papers are fundementals to this research field and a must know for a qualified Ph.D. student for AI related majors.]{.aside}
^2^ Matching networks for one shot learning, 2016 [Read paper](https://proceedings.neurips.cc/paper/2016/hash/90e1357833654983612fb05e3ec9148c-Abstract.html)<br>
^3^ Understanding deep learning requires rethinking generalization, 2016 [Read paper](https://arxiv.org/abs/1611.03530)<br>
^4^ Deep double descent: Where bigger models and more data hur, 2021 [Read paper](https://iopscience.iop.org/article/10.1088/1742-5468/ac3a74/meta)<br>
^5^ Auto-Encoding Variational Bayes, 2013 [Read paper](https://arxiv.org/abs/1312.6114)<br>
^6^ Visualizing the loss landscape of neural nets, 2018 [Read paper](https://proceedings.neurips.cc/paper/2018/hash/a41b3bb3e6b050b6c9067c67f663b915-Abstract.html)

### Module 2: Discriminative Models

| Week | Date | Lesson 1 | Lesson 2 | Lesson 3 | Materials |
|:----:|:----:|:--------:|:--------:|:--------:|:---------:|
| **5** | 10/09/2025 | *Lecture* | *Lecture* | *Lecture* | [Slides](lecture_3.pdf) |
| **6** | 10/16/2025 | *Lecture* | üßëüèº‚Äçüè´üë©üèº‚Äçüè´<span style="color: darkred !important;">*Presentation II*</span> | *Coding II* | [Slides](lecture_4.pdf) [GP](code_2_gp.ipynb), [PyTorch](code_2_PyTorch.ipynb), [Neural Networks](code_2_neural_network.ipynb) |
| **7** | 10/23/2025 | *Reading*^7^ | *Reading*^8^ | *Reading*^9^ | |

^7^ A simple framework for contrastive learning of visual representations, 2020 [Read paper](https://proceedings.mlr.press/v119/chen20j.html)<br>
^8^ An image is worth 16x16 words: Transformers for image recognition at scale, 2020 [Read paper](https://arxiv.org/abs/2010.11929)<br>
^9^ Flamingo: a visual language model for few-shot learning, 2022 [Read paper](https://proceedings.neurips.cc/paper_files/paper/2022/hash/960a172bc7fbf0177ccccbb411a7d800-Abstract-Conference.html)

### Module 3: Reinforcement Learning

| Week | Date | Lesson 1 | Lesson 2 | Lesson 3 | Materials |
|:----:|:----:|:--------:|:--------:|:--------:|:---------:|
| **8** | 10/30/2025 | *Lecture* | *Lecture* | *Lecture* | [Slides](lecture_5.pdf) |
| **9** | 11/06/2025 | *Lecture* | üßëüèº‚Äçüè´üë©üèº‚Äçüè´<span style="color: darkred !important;">*Presentation III*</span> | *Coding III* | [Slides](lecture_6.pdf) [Q_Learning](code_3_q_learning.ipynb), [REINFORCE](code_3_reinforce.ipynb) |
| **10** | 11/13/2025 | *Reading*^10^ | *Reading*^11^ | *Reading*^12^ | |

^10^ Proximal policy optimization algorithms, 2017 [Read paper](https://arxiv.org/abs/1707.06347)<br>
^11^ BOHB: Robust and efficient hyperparameter optimization at scale, 2018 [Read paper](https://proceedings.mlr.press/v80/falkner18a.html)<br>
^12^ Deep reinforcement learning from human preferences, 2017 [Read paper](https://proceedings.neurips.cc/paper/7017-deep-reinforcement-learning-from-human-preferences)

### Module 4: Generative Models

| Week | Date | Lesson 1 | Lesson 2 | Lesson 3 | Materials |
|:----:|:----:|:--------:|:--------:|:--------:|:---------:|
| **11** | 11/20/2025 | *Lecture* | *Lecture* | *Lecture* | [Slides](lecture_7.pdf) |
| **12** | 11/27/2025 | *Reading*^13^ | *Reading*^14^ | *Reading*^15^ | |
| **13** | 12/04/2025 | *Lecture* | üßëüèº‚Äçüè´üë©üèº‚Äçüè´<span style="color: darkred !important;">*Presentation IV*</span> | *Coding IV* | [Slides](lecture_8.pdf) [VAE](code_4_vae.ipynb), [VQ_VAE](code_4_vqvae.ipynb) |

^13^ Pixel Recurrent Neural Networks, 2016 [Read paper](https://proceedings.mlr.press/v48/oord16.html)<br>
^14^ Deep Image Prior, 2018 [Read paper](http://openaccess.thecvf.com/content_cvpr_2018/html/Ulyanov_Deep_Image_Prior_CVPR_2018_paper.html) <br>
^15^ Scaling Rectified Flow Transformers for High-Resolution Image Synthesis, 2024 [Read paper](https://openreview.net/forum?id=FPnUhsQJ5B)

### Module 5: Emerging Topics

| Week | Date | Lesson 1 | Lesson 2 | Lesson 3 | Materials |
|:----:|:----:|:--------:|:--------:|:--------:|:---------:|
| **14** | 12/11/2025 | *Lecture* | *Lecture* | *Lecture* | [Slides](lecture_9.pdf) |
| **15** | 12/18/2025 | *Lecture* | üßëüèº‚Äçüè´üë©üèº‚Äçüè´<span style="color: darkred !important;">*Presentation V*</span> | *Coding V* | [Slides](lecture_10.pdf) [ICL_CLS](code_5_icl_classification.ipynb), [ICL_REG](code_5_icl_regression.ipynb) |
| **16** | 12/25/2025 | *Reading*^16^ | *Reading*^17^ | *Reading*^18^ | |
| **17** | 01/01/2026 | | |üìÜFinal | |

^16^ Highly accurate protein structure prediction with AlphaFold, 2021 [Read paper](https://www.nature.com/articles/s41586-021-03819-2)<br>
^17^ Learnable latent embeddings for joint behavioural and neural analysis, 2023 [Read paper](https://www.nature.com/articles/s41586-023-06031-6)<br>
^18^ Generative models improve fairness of medical classifiers under distribution shifts, 2024 [Read paper](https://www.nature.com/articles/s41591-024-02838-6)

## Course Components

### Presentation Sections

::: {.presentation-info}
- **Slots**: **5** sessions (~10 slots, 20 students) (üßëüèº‚Äçüè´üë©üèº‚Äçüè´<span style="color: darkred !important;">*Pres.*</span>) throughout the semester
- **Group Size**: Maximum 2 people per group
- **Duration**: 15 minutes presentation + 5 minutes Q&A
- **Format**: Interactive presentations with Q&A sessions
:::

### Coding Sections

::: {.coding-info}
- **Slots**: **5** sessions (I will prepare the materials) throughout the semester
- **Hands-on Programming**: Practical implementation of algorithms
- **Languages**: Python
- **Environment**: Jupyter notebooks, potentially with Google Colab

**Note**: These coding sessions are **optional**. Students are not required to stay in the classroom during these sessions.
:::

### Reading Sections

::: {.reading-info}
- **Slots**: **18** sessions throughout the semester
I will provide a list of reading papers, and you should read them independently at your own pace.

**Note**: Please submit annotated PDFs of at least two papers to demonstrate your in-depth reading and analysis alongside your final project submission.
:::

### Final Project

::: {.course-description}
- **Due Date**: Week 17, January 1, 2026, 23:59 China Standard Time (CST)  
- **Submission**: Please submit the following via email to zejuli@fudan.edu.cn:
-- 1. Your final project draft
-- 2. At least two annotated reading papers

**Note**: The final project can be completed in **one** of the following formats:

- **Scientific Blog**: Present important course-related concepts in a rigorous, comprehensive, and pedagogically meaningful manner. Examples: [Distill](https://distill.pub/), [ICLR Blog](https://iclr-blogposts.github.io/2025/blog/).

- **Research Report**: Conduct innovative research in the field of pattern recognition, with results that meet the standards of top-tier AI conference workshops.
:::

### Grading Policy

| Component | Weight | Description |
|:---------:|:------:|:------------|
| **Presentations** | 30% | Clarity, relevance, and presentation layout |
| **Final Project** | 60% | Research depth and technical writing |
| **Participation** | 10% | Demonstrate engagement with paper reading |

## Recommended Reading Materials

### Core Pattern Recognition & Machine Learning
- [Pattern Recognition and Machine Learning](https://www.microsoft.com/en-us/research/publication/pattern-recognition-machine-learning/) - Christopher Bishop's comprehensive textbook on pattern recognition
- [Êú∫Âô®Â≠¶‰π†](https://github.com/Mikoto10032/DeepLearning/blob/master/books/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E5%91%A8%E5%BF%97%E5%8D%8E.pdf) - Âë®ÂøóÂçé's foundational machine learning textbook (in Chinese)

### Deep Learning
- [Deep Learning](https://www.deeplearningbook.org/) - Ian Goodfellow, Yoshua Bengio, and Aaron Courville's authoritative deep learning textbook
- [Dive into Deep Learning](https://d2l.ai/) - Interactive deep learning book with practical implementations

### Mathematical Foundations
- [Mathematics for Machine Learning](https://mml-book.github.io/) - Essential mathematical concepts for machine learning
- [Machine Learning: A Probabilistic Perspective](https://github.com/Jing--Li/book/blob/master/ML%20Machine%20Learning-A%20Probabilistic%20Perspective.pdf) - Kevin Murphy's detailed treatment of machine learning from a probabilistic viewpoint

### Medical Imaging & Domain-Specific Applications
- [Generative Machine Learning Models in Medical Image Computing](https://link.springer.com/book/10.1007/978-3-031-80965-1) - Specialized book on generative models in medical imaging
- [Machine Learning in MRI](https://shop.elsevier.com/books/machine-learning-in-mri/kuestner/978-0-443-14109-6) - Focused on machine learning applications in magnetic resonance imaging
